{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "PKCczpbOHOwl",
        "KLMyAp4wKGC0"
      ],
      "authorship_tag": "ABX9TyNORmJtNOZTaXoell/LOQTl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor-lyhan/Parkinson-Diagnosis/blob/main/nlp_Parkinson's_Diagnose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Tests\n"
      ],
      "metadata": {
        "id": "styUeZPaHF32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "PKCczpbOHOwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEWLzmusGtrZ",
        "outputId": "acc4b7ff-c7b6-4e63-d6e7-a773b25f33d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Computer science is the study of computation, automation, and information. Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software). Computer science is generally considered an academic discipline and distinct from computer programming\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhhprJduJvMx",
        "outputId": "aea800d0-a681-47d5-ff62-6aa88ca54dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Computer science is the study of computation, automation, and information.',\n",
              " 'Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software).',\n",
              " 'Computer science is generally considered an academic discipline and distinct from computer programming']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Stop Words\n",
        "\n",
        "I love you\n",
        "\n",
        "I hate you"
      ],
      "metadata": {
        "id": "KLMyAp4wKGC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(stop_words)\n",
        "\n",
        "filter_words = []\n",
        "for t in tokens:\n",
        "  if t not in stop_words:\n",
        "    filter_words.append(t)\n",
        "\n",
        "print(filter_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocJEnI1xKP1E",
        "outputId": "17fdbb7d-5234-43c7-dc90-697765bcb134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'it', 'my', 'i', \"she's\", 'haven', 'wasn', 'do', 'yours', 'hasn', 'wouldn', 'have', 'own', 'them', 'where', 'to', 'most', 'o', 'by', 'doesn', 'ourselves', 'on', 'then', 'itself', 'before', 'or', 'having', 'a', 'against', 've', 'nor', 'themselves', 'what', 'were', 'with', \"shouldn't\", 'off', 'no', 'isn', \"won't\", 'between', 'same', 'very', \"don't\", 'all', 'shouldn', 'her', 'over', 'hadn', 'any', 'your', 'does', 'him', 'ain', 'had', 'why', 'some', \"mustn't\", 'while', 'because', 'up', 'for', 't', 'yourself', 'now', 'there', 'here', \"couldn't\", \"mightn't\", 'theirs', 'didn', 'but', \"didn't\", \"shan't\", 'their', \"you've\", 'm', 'was', 'yourselves', 'more', 'shan', 'until', \"you'll\", 'once', 'has', 'be', 'they', 'himself', 'hers', 'too', 'you', 'and', 'mightn', 'me', 'won', 'which', 'couldn', 'can', \"haven't\", 's', 'both', 'he', 'not', 'such', 'just', \"needn't\", \"you'd\", 'doing', \"hadn't\", 'from', 'at', 'are', 'other', 'needn', \"that'll\", 'so', 'through', 'been', 'its', 'we', \"weren't\", 'out', 'being', 'under', \"wasn't\", 'during', 'in', 'about', 'if', 'into', 'as', 'above', 'don', 'after', 'aren', 'myself', 'she', 'our', 'of', 'again', 'mustn', \"it's\", 'down', 'am', 'his', 'who', 'an', 'each', \"isn't\", \"wouldn't\", \"aren't\", 'these', 'when', 'only', 'herself', 'the', 'than', \"should've\", 'further', \"doesn't\", 'is', 'few', 'that', 'ma', 'ours', \"hasn't\", 'll', 'whom', 'this', 'did', 'those', 'should', 'below', 're', 'y', 'will', \"you're\", 'd', 'weren', 'how'}\n",
            "['Computer', 'science', 'study', 'computation', ',', 'automation', ',', 'information', '.', 'Computer', 'science', 'spans', 'theoretical', 'disciplines', '(', 'algorithms', ',', 'theory', 'computation', ',', 'information', 'theory', ',', 'automation', ')', 'practical', 'disciplines', '(', 'including', 'design', 'implementation', 'hardware', 'software', ')', '.', 'Computer', 'science', 'generally', 'considered', 'academic', 'discipline', 'distinct', 'computer', 'programming']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stem"
      ],
      "metadata": {
        "id": "houK7EhiMw_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_words(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_words.append(lematizer.lemmatize(word))\n",
        "    return new_words\n",
        "\n",
        "lemmatize_words([\"cats\", \"cacti\", \"geese\", 'goose'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HYL_kwZNhbX",
        "outputId": "78b81a96-9f9a-46d1-9401-a26feef552ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'cactus', 'goose', 'goose']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parkinson's Diagnose"
      ],
      "metadata": {
        "id": "kGDCjCD27110"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## counting pos"
      ],
      "metadata": {
        "id": "6wQQ03Ow8u6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = \"Computer science is the study of computation, automation, and information.\"\\\n",
        "\"Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software).\"\\\n",
        "\"Computer science is generally considered an academic discipline and distinct from computer programming.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPsS5RBY9RjC",
        "outputId": "2995c83c-e99a-4c43-aafe-e1e90945d481"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* verbs - VB\tverb (ask)\n",
        "VBG\tverb gerund (judging)\n",
        "VBD\tverb past tense (pleaded)\n",
        "VBN\tverb past participle (reunified)\n",
        "VBP\tverb, present tense not 3rd person singular(wrap)\n",
        "VBZ\tverb, present tense with 3rd person singular (bases)\n",
        "* common nouns - NN, NNS\n",
        "* proper nouns - NNP, NNPS\n"
      ],
      "metadata": {
        "id": "1v58QMikBnZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filler_words = [\n",
        "    \"um\", \"uh\", \"er\", \"like\", \"you know\", \"i mean\", \"well\", \"so\", \"okay\", \"right\",\n",
        "    \"actually\", \"basically\", \"literally\", \"kind of\", \"sort of\", \"anyway\", \"or something\",\n",
        "    \"whatever\", \"i guess\", \"you see\", \"got it\", \"i suppose\", \"just\", \"yeah\", \"yep\",\n",
        "    \"seriously\", \"alright\", \"hmm\", \"look\", \"totally\", \"alright then\", \"know what i mean?\",\n",
        "    \"at the end of the day\", \"to be honest\", \"if you know what i mean\"\n",
        "]\n",
        "\n",
        "def pdFeaturesCount(tokens):\n",
        "  wordList = pos_tag(word_tokenize(tokens))\n",
        "  totalWords, verbsRate, verbs, commonNouns, properNouns, fillers = 0, 0, 0, 0, 0, 0\n",
        "  for word, pos in wordList:\n",
        "    #print(word, pos)\n",
        "    totalWords += 1\n",
        "    if pos in ['VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']:\n",
        "      verbs += 1\n",
        "    if pos in ['NN', 'NNS']:\n",
        "      commonNouns += 1\n",
        "    if pos in ['NNP', 'NNPS']:\n",
        "      properNouns += 1\n",
        "    if word in filler_words:\n",
        "      fillers += 1\n",
        "  verbsRate = verbs / totalWords\n",
        "  return totalWords, verbsRate, verbs, commonNouns, properNouns, fillers"
      ],
      "metadata": {
        "id": "O2VPwr9A-OET"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdFeaturesCount(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYThN75NAFt4",
        "outputId": "363b1c18-bb7a-4b46-dee3-7de5b1e6fa3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59, 0.06779661016949153, 4, 25, 1, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}