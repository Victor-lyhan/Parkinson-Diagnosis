{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGDCjCD27110"
      },
      "source": [
        "# Parkinson's Diagnose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/Users/hanliyang/Documents/GitHub/Parkinson-Prediagnosis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Audio Conversion\n",
        "* Using assembly AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"d9ccd193e5e54a4ca8bdddaf3769bc59\"\n",
        "\n",
        "config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "audioPath = \"\"\n",
        "\n",
        "def audioTextConversion(audioPath):\n",
        "    dialogue = {\n",
        "        \"Speaker A\" : [],\n",
        "        \"Speaker B\" : []\n",
        "    }\n",
        "    transcript = transcriber.transcribe(\n",
        "    audioPath,\n",
        "    config=config\n",
        "    )\n",
        "\n",
        "    for utterance in transcript.utterances:\n",
        "        #print(f\"Speaker {utterance.speaker}: {utterance.text}\")\n",
        "        speaker = f\"Speaker {utterance.speaker}\"\n",
        "        dialogue[speaker].append(utterance.text)\n",
        "    return speaker_differentiation(dialogue)\n",
        "    \n",
        "def speaker_differentiation(dialogue):\n",
        "    totalA = 0\n",
        "    totalB = 0\n",
        "    for text in dialogue['Speaker A']:\n",
        "        totalA += len(text)\n",
        "    \n",
        "    for text in dialogue['Speaker B']:\n",
        "        totalB += len(text)\n",
        "\n",
        "    if totalA > totalB:\n",
        "        return {'participant':' '.join(dialogue[\"Speaker A\"]), \n",
        "                \"interviewer\": ' '.join(dialogue[\"Speaker B\"])} \n",
        "    else:\n",
        "        return {'participant':' '.join(dialogue[\"Speaker B\"]), \n",
        "                \"interviewer\": ' '.join(dialogue[\"Speaker A\"])} \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speaker A: Okay, great. Thank you.\n",
            "Speaker B: Thank you.\n",
            "Speaker A: I would try the spontaneous dialogue. So I will start with a question. For example, it's my first time in London and could you recommend some place nice places I should visit?\n",
            "Speaker B: St. James's park in London. And Buckingham palace and. Sorry. Now what other places? Trafalgar Square. Trafalgar Square. And.\n",
            "Speaker C: Buckingham Palace.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Speaker C'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dialogue \u001b[38;5;241m=\u001b[39m \u001b[43maudioTextConversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLP/Data/SpontaneousDialogue/HC/ID31_hc_0_1_1.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#df = pd.DataFrame(data = dialogue)\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[53], line 24\u001b[0m, in \u001b[0;36maudioTextConversion\u001b[0;34m(audioPath)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutterance\u001b[38;5;241m.\u001b[39mspeaker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutterance\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutterance\u001b[38;5;241m.\u001b[39mspeaker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mdialogue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(utterance\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m speaker_differentiation(dialogue)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Speaker C'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dialogue = audioTextConversion('NLP/Data/SpontaneousDialogue/HC/ID00_hc_0_0_0.wav')\n",
        "\n",
        "#df = pd.DataFrame(data = dialogue)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'participant': \"Hi. Yeah. In London, you can go to Oxford street, which is famous for shopping, and there's selfishes there, and a lot of tourists come there and a lot there. So it's a good place to see when you come to London. And there's Buckingham palace, where the Queen lives, and that's a good place, the way the royal family lives. So you can come there. And there's other big Ben houses of parliament, where the government. The government are british government are. So that's good places to go. And then there's the London Eye, where you can see the whole of London. You go and you can see the whole of London. So that's good places to visit in London. Yeah. So if I was. I was coming, would you recommend. I think, yeah, I would go by public transport. Then you would see how London really is, and you see the whole of London. If you go on a bus or the transport, you would see how London is. So I would advise to go on public transport, buses and trains, so you'd really enjoy it. And you could get on an open tour bus, where you can see the whole of London and go around. It doesn't cost that much, so, yeah, that's good. Yeah, you can see more of London. Yeah. Okay, then. Bye.\",\n",
              " 'interviewer': \"Okay, so it's my first time in London, and maybe you can give me some tips for sightseeing. Okay. So that's enough. Thank you.\"}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dialogue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQQ03Ow8u6J"
      },
      "source": [
        "## Counting Pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPsS5RBY9RjC",
        "outputId": "2995c83c-e99a-4c43-aafe-e1e90945d481"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/hanliyang/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/hanliyang/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = \"Computer science is the study of computation, automation, and information.\"\\\n",
        "\"Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software).\"\\\n",
        "\"Computer science is generally considered an academic discipline and distinct from computer programming.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v58QMikBnZc"
      },
      "source": [
        "* verbs - VB\tverb (ask)\n",
        "VBG\tverb gerund (judging)\n",
        "VBD\tverb past tense (pleaded)\n",
        "VBN\tverb past participle (reunified)\n",
        "VBP\tverb, present tense not 3rd person singular(wrap)\n",
        "VBZ\tverb, present tense with 3rd person singular (bases)\n",
        "* common nouns - NN, NNS\n",
        "* proper nouns - NNP, NNPS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "O2VPwr9A-OET"
      },
      "outputs": [],
      "source": [
        "filler_words = [\n",
        "    \"um\", \"uh\", \"er\", \"like\", \"you know\", \"i mean\", \"well\", \"so\", \"okay\", \"right\",\n",
        "    \"actually\", \"basically\", \"literally\", \"kind of\", \"sort of\", \"anyway\", \"or something\",\n",
        "    \"whatever\", \"i guess\", \"you see\", \"got it\", \"i suppose\", \"just\", \"yeah\", \"yep\",\n",
        "    \"seriously\", \"alright\", \"hmm\", \"look\", \"totally\", \"alright then\", \"know what i mean?\",\n",
        "    \"at the end of the day\", \"to be honest\", \"if you know what i mean\"\n",
        "]\n",
        "\n",
        "def pdFeaturesCount(tokens):\n",
        "  wordList = pos_tag(word_tokenize(tokens))\n",
        "  totalWords, verbsRate, verbs, commonNouns, properNouns, fillers = 0, 0, 0, 0, 0, 0\n",
        "  for word, pos in wordList:\n",
        "    #print(word, pos)\n",
        "    totalWords += 1\n",
        "    if pos in ['VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']:\n",
        "      verbs += 1\n",
        "    if pos in ['NN', 'NNS']:\n",
        "      commonNouns += 1\n",
        "    if pos in ['NNP', 'NNPS']:\n",
        "      properNouns += 1\n",
        "    if word in filler_words:\n",
        "      fillers += 1\n",
        "\n",
        "  verbsRate = round(verbs / totalWords, 3)\n",
        "  commonNounsRate = round(commonNouns / totalWords, 3)\n",
        "  properNounsRate = round(properNouns / totalWords, 3)\n",
        "  fillersRate = round(fillers / totalWords, 3)\n",
        "\n",
        "  return {'Total Words': totalWords, 'Vb Rate': verbsRate, 'Verbs': verbs, 'CmN rate': commonNounsRate, 'Common Nouns': commonNouns, 'PpN Rate': properNounsRate, 'Proper Nouns': properNouns, 'FlR': fillersRate, 'Filler Words': fillers}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYThN75NAFt4",
        "outputId": "363b1c18-bb7a-4b46-dee3-7de5b1e6fa3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'participant': \"Hi. Yeah. In London, you can go to Oxford street, which is famous for shopping, and there's selfishes there, and a lot of tourists come there and a lot there. So it's a good place to see when you come to London. And there's Buckingham palace, where the Queen lives, and that's a good place, the way the royal family lives. So you can come there. And there's other big Ben houses of parliament, where the government. The government are british government are. So that's good places to go. And then there's the London Eye, where you can see the whole of London. You go and you can see the whole of London. So that's good places to visit in London. Yeah. So if I was. I was coming, would you recommend. I think, yeah, I would go by public transport. Then you would see how London really is, and you see the whole of London. If you go on a bus or the transport, you would see how London is. So I would advise to go on public transport, buses and trains, so you'd really enjoy it. And you could get on an open tour bus, where you can see the whole of London and go around. It doesn't cost that much, so, yeah, that's good. Yeah, you can see more of London. Yeah. Okay, then. Bye.\",\n",
              " 'interviewer': \"Okay, so it's my first time in London, and maybe you can give me some tips for sightseeing. Okay. So that's enough. Thank you.\",\n",
              " 'Total Words': 286,\n",
              " 'Vb Rate': 0.154,\n",
              " 'Verbs': 44,\n",
              " 'CmN rate': 0.108,\n",
              " 'Common Nouns': 31,\n",
              " 'PpN Rate': 0.077,\n",
              " 'Proper Nouns': 22,\n",
              " 'FlR': 0.014,\n",
              " 'Filler Words': 4}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dialogue.update(pdFeaturesCount(dialogue['participant']))\n",
        "dialogue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Iterating through the actual audios\n",
        "* 0 -- HC\n",
        "* 1 -- PD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLP/Data/SpontaneousDialogue/PD/ID32_pd_3_1_1.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID30_pd_2_1_1.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID06_pd_3_1_1.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID27_pd_4_1_1.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID24_pd_2_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID13_pd_3_2_2.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID29_pd_3_1_2.wav\n",
            "NLP/Data/SpontaneousDialogue/PD/ID07_pd_2_0_0.wav\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "data = []\n",
        "\n",
        "for path in glob.glob('NLP/Data/SpontaneousDialogue/PD/*'):\n",
        "    dialogue = {}\n",
        "    dialogue['target'] = 1\n",
        "    dialogue['Audio path'] = path\n",
        "    print(path)\n",
        "    dialogue.update(audioTextConversion(path))\n",
        "    dialogue.update(pdFeaturesCount(dialogue['participant']))\n",
        "    data.append(dialogue)\n",
        "\n",
        "#31 HC not passed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLP/Data/SpontaneousDialogue/HC/ID01_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID14_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID25_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID12_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID15_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID00_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID36_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID23_hc_0_0_0.wav\n",
            "NLP/Data/SpontaneousDialogue/HC/ID28_hc_0_0_0.wav\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(data)):\n",
        "    print(data[i]['Audio path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data).reset_index(drop=True)\n",
        "df1 = pd.read_csv('NLP/Data/SpontaneousDialogue/PD_Data.csv')\n",
        "df = pd.concat([df,df1], axis=0)\n",
        "df.to_csv('NLP/Data/SpontaneousDialogue/PD_Data.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNORmJtNOZTaXoell/LOQTl",
      "collapsed_sections": [
        "PKCczpbOHOwl",
        "KLMyAp4wKGC0"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
