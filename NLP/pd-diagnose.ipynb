{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGDCjCD27110"
      },
      "source": [
        "# Parkinson's Diagnose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/Users/hanliyang/Documents/GitHub/Parkinson-Prediagnosis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Audio Conversion\n",
        "* Using assembly AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"d9ccd193e5e54a4ca8bdddaf3769bc59\"\n",
        "\n",
        "config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "audioPath = \"\"\n",
        "\n",
        "def audioTextConversion(audioPath):\n",
        "    dialogue = {\n",
        "        \"Speaker A\" : [],\n",
        "        \"Speaker B\" : []\n",
        "    }\n",
        "    transcript = transcriber.transcribe(\n",
        "    audioPath,\n",
        "    config=config\n",
        "    )\n",
        "\n",
        "    for utterance in transcript.utterances:\n",
        "        print(f\"Speaker {utterance.speaker}: {utterance.text}\")\n",
        "        speaker = f\"Speaker {utterance.speaker}\"\n",
        "        dialogue[speaker].append(utterance.text)\n",
        "    return speaker_differentiation(dialogue)\n",
        "    \n",
        "def speaker_differentiation(dialogue):\n",
        "    totalA = 0\n",
        "    totalB = 0\n",
        "    for text in dialogue['Speaker A']:\n",
        "        totalA += len(text)\n",
        "    \n",
        "    for text in dialogue['Speaker B']:\n",
        "        totalB += len(text)\n",
        "\n",
        "    if totalA > totalB:\n",
        "        return {'participant':str(dialogue[\"Speaker A\"]), \n",
        "                \"interviewer\": str(dialogue[\"Speaker B\"])} \n",
        "    else:\n",
        "        return {'participant':str(dialogue[\"Speaker B\"]), \n",
        "                \"interviewer\": str(dialogue[\"Speaker A\"])} \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Spaeaker A'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dialogue \u001b[38;5;241m=\u001b[39m \u001b[43maudioTextConversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLP/Data/SpontaneousDialogue/HC/ID00_hc_0_0_0.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data \u001b[38;5;241m=\u001b[39m dialogue)\n",
            "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36maudioTextConversion\u001b[0;34m(audioPath)\u001b[0m\n\u001b[1;32m     23\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutterance\u001b[38;5;241m.\u001b[39mspeaker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     dialogue[speaker]\u001b[38;5;241m.\u001b[39mappend(utterance\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspeaker_differentiation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[11], line 30\u001b[0m, in \u001b[0;36mspeaker_differentiation\u001b[0;34m(dialogue)\u001b[0m\n\u001b[1;32m     28\u001b[0m totalA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     29\u001b[0m totalB \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdialogue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpaeaker A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     31\u001b[0m     totalA \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m dialogue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaker B\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Spaeaker A'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dialogue = audioTextConversion('NLP/Data/SpontaneousDialogue/HC/ID00_hc_0_0_0.wav')\n",
        "\n",
        "df = pd.DataFrame(data = dialogue)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQQ03Ow8u6J"
      },
      "source": [
        "## Counting Pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPsS5RBY9RjC",
        "outputId": "2995c83c-e99a-4c43-aafe-e1e90945d481"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/hanliyang/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/hanliyang/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = \"Computer science is the study of computation, automation, and information.\"\\\n",
        "\"Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software).\"\\\n",
        "\"Computer science is generally considered an academic discipline and distinct from computer programming.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v58QMikBnZc"
      },
      "source": [
        "* verbs - VB\tverb (ask)\n",
        "VBG\tverb gerund (judging)\n",
        "VBD\tverb past tense (pleaded)\n",
        "VBN\tverb past participle (reunified)\n",
        "VBP\tverb, present tense not 3rd person singular(wrap)\n",
        "VBZ\tverb, present tense with 3rd person singular (bases)\n",
        "* common nouns - NN, NNS\n",
        "* proper nouns - NNP, NNPS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "O2VPwr9A-OET"
      },
      "outputs": [],
      "source": [
        "filler_words = [\n",
        "    \"um\", \"uh\", \"er\", \"like\", \"you know\", \"i mean\", \"well\", \"so\", \"okay\", \"right\",\n",
        "    \"actually\", \"basically\", \"literally\", \"kind of\", \"sort of\", \"anyway\", \"or something\",\n",
        "    \"whatever\", \"i guess\", \"you see\", \"got it\", \"i suppose\", \"just\", \"yeah\", \"yep\",\n",
        "    \"seriously\", \"alright\", \"hmm\", \"look\", \"totally\", \"alright then\", \"know what i mean?\",\n",
        "    \"at the end of the day\", \"to be honest\", \"if you know what i mean\"\n",
        "]\n",
        "\n",
        "def pdFeaturesCount(tokens):\n",
        "  wordList = pos_tag(word_tokenize(tokens))\n",
        "  totalWords, verbsRate, verbs, commonNouns, properNouns, fillers = 0, 0, 0, 0, 0, 0\n",
        "  for word, pos in wordList:\n",
        "    #print(word, pos)\n",
        "    totalWords += 1\n",
        "    if pos in ['VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']:\n",
        "      verbs += 1\n",
        "    if pos in ['NN', 'NNS']:\n",
        "      commonNouns += 1\n",
        "    if pos in ['NNP', 'NNPS']:\n",
        "      properNouns += 1\n",
        "    if word in filler_words:\n",
        "      fillers += 1\n",
        "  verbsRate = verbs / totalWords\n",
        "  return totalWords, verbsRate, verbs, commonNouns, properNouns, fillers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYThN75NAFt4",
        "outputId": "363b1c18-bb7a-4b46-dee3-7de5b1e6fa3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(59, 0.06779661016949153, 4, 25, 1, 0)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdFeaturesCount(tokens)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNORmJtNOZTaXoell/LOQTl",
      "collapsed_sections": [
        "PKCczpbOHOwl",
        "KLMyAp4wKGC0"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
